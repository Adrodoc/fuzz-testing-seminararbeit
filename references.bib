% Encoding: UTF-8

@article{TSE12_EvoSuite,
 author = {Gordon Fraser and Andrea Arcuri},
 title = {Whole Test Suite Generation},
 journal ={IEEE Transactions on Software Engineering},
 year={2013},
 month={feb. },
 volume={39},
 number={2},
 pages={276 -291},
 abstract={Not all bugs lead to program crashes, and not always is there a formal specification to check the correctness of a software test's outcome. A common scenario in software testing is therefore that test data are generated, and a tester manually adds test oracles. As this is a difficult task, it is important to produce small yet representative test sets, and this representativeness is typically measured using code coverage. There is, however, a fundamental problem with the common approach of targeting one coverage goal at a time: Coverage goals are not independent, not equally difficult, and sometimes infeasible-the result of test generation is therefore dependent on the order of coverage goals and how many of them are feasible. To overcome this problem, we propose a novel paradigm in which whole test suites are evolved with the aim of covering all coverage goals at the same time while keeping the total size as small as possible. This approach has several advantages, as for example, its effectiveness is not affected by the number of infeasible targets in the code. We have implemented this novel approach in the EvoSuite tool, and compared it to the common approach of addressing one goal at a time. Evaluated on open source libraries and an industrial case study for a total of 1,741 classes, we show that EvoSuite achieved up to 188 times the branch coverage of a traditional approach targeting single branches, with up to 62 percent smaller test suites.},
 keywords={Arrays;Genetic algorithms;Genetic programming;Search problems;Software;Software testing;formal specification;program debugging;program testing;EvoSuite tool;code coverage;formal specification;program crashes;program debugging;software testing;whole test suite generation;Search-based software engineering;branch coverage;collateral coverage;genetic algorithm;infeasible goal;length;},
 doi={10.1109/TSE.2012.14},
 ISSN={0098-5589},
 url = {http://www.evosuite.org/wp-content/papercite-data/pdf/tse12_evosuite.pdf},
}

@article{10.1109/32.57624,
 author = {Korel, B.},
 title = {Automated Software Test Data Generation},
 year = {1990},
 issue_date = {August 1990},
 publisher = {IEEE Press},
 volume = {16},
 number = {8},
 issn = {0098-5589},
 url = {https://doi.org/10.1109/32.57624},
 doi = {10.1109/32.57624},
 journal = {IEEE Trans. Softw. Eng.},
 month = aug,
 pages = {870–879},
 numpages = {10},
 keywords = {function-minimization search algorithms, backtracking, program testing, input variables, search problems., dynamic data structures, data structures, dynamic data-flow analysis, function-minimization methods, minimisation, array indexes, pointers, automated software test data generation, program behavior, automatic programming, program execution flow}
}

@article{emse14_mutation,
   author={Fraser, Gordon and Arcuri, Andrea},
   year={2014},
   journal={Empirical Software Engineering},
   title={Achieving Scalable Mutation-based Generation of Whole Test Suites},
   publisher={Springer US},
   language={English},
   volume={20},
   number={3},
   pages={783--812},
   url = {http://www.evosuite.org/wp-content/papercite-data/pdf/emse14_mutation.pdf},
}

@article{TSE12_Mutation,
 author = {Gordon Fraser and Andreas Zeller},
 title = {Mutation-Driven Generation of Unit Tests and Oracles},
 journal ={IEEE Transactions on Software Engineering},
 year={2012},
 volume={38},
 number={2},
 pages={278--292},
 month={march-april },
 issn = {0098-5589},
 publisher = {IEEE Computer Society},
 address = {Los Alamitos, CA, USA},
 keywords={artificial defects;automated test case generation;mutation driven generation;mutation operators;object-oriented classes;open source libraries;optimization;oracle;test suites quality;unit test;automatic test pattern generation;object-oriented programming;optimisation;program testing;},
 doi={10.1109/TSE.2011.93},
 url = {http://www.evosuite.org/wp-content/papercite-data/pdf/tse12_mutation.pdf},
}

@inproceedings{10.5555/3105427.3105434,
author = {Panichella, Annibale and Molina, Urko Rueda},
title = {Java Unit Testing Tool Competition: Fifth Round},
year = {2017},
isbn = {9781538627891},
publisher = {IEEE Press},
booktitle = {Proceedings of the 10th International Workshop on Search-Based Software Testing},
pages = {32–38},
numpages = {7},
keywords = {Java, automated unit testing, benchmark, mutation testing, statistical analysis, tool competition},
location = {Buenos Aires, Argentina},
series = {SBST ’17}
}

@inproceedings{10.1145/2897010.2897018,
author = {Rueda, Urko and Just, Ren\'{e} and Galeotti, Juan P. and Vos, Tanja E. J.},
title = {Unit Testing Tool Competition: Round Four},
year = {2016},
isbn = {9781450341660},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2897010.2897018},
doi = {10.1145/2897010.2897018},
booktitle = {Proceedings of the 9th International Workshop on Search-Based Software Testing},
pages = {19–28},
numpages = {10},
keywords = {mutation testing, defects4j, Java, benchmark, automated unit testing, tool competition},
location = {Austin, Texas},
series = {SBST ’16}
}

@article{TOSEM_userstudy,
 author = {Gordon Fraser and Matt Staats and Phil McMinn and Andrea Arcuri and Frank Padberg},
 title = {Does Automated Unit Test Generation Really Help Software Testers? A Controlled Empirical Study},
 journal = {ACM Transactions on Software Engineering and Methodology (TOSEM)},
  volume = {24},
  number = {4},
  pages = {23},
  year = {2015},
  publisher = {ACM},
  url = {http://www.evosuite.org/wp-content/papercite-data/pdf/tosem_userstudy.pdf},
}
